---

## ğŸ–ï¸ MotionControl - AutomaÃ§Ã£o com Gestos das MÃ£os

"Controle total com um movimento: a tecnologia na ponta dos dedos."

Sistema de automaÃ§Ã£o que permite controlar aÃ§Ãµes do computador por meio de gestos com as mÃ£os, utilizando webcam e bibliotecas de visÃ£o computacional. Esse projeto foi o trabalho final da disciplina de AutomaÃ§Ã£o e IntegraÃ§Ã£o no curso TÃ©cnico em Desenvolvimento de Sistemas.

<div align="center">
  <img src="https://img.shields.io/badge/Status-Conclu%C3%ADdo-1B67A4?style=for-the-badge&logo=visualstudio&logoColor=white"/>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/OpenCV-27338e?style=for-the-badge&logo=opencv&logoColor=white"/>
  <img src="https://img.shields.io/badge/MediaPipe-FF6F00?style=for-the-badge&logo=google&logoColor=white"/>
  <img src="https://img.shields.io/badge/PyAutoGUI-00BFFF?style=for-the-badge&logo=python&logoColor=white"/>
</div>

---

### ğŸ§  Sobre o Projeto

A proposta foi criar uma ferramenta prÃ¡tica de acessibilidade e automaÃ§Ã£o, reconhecendo movimentos da mÃ£o captados por uma cÃ¢mera e transformando-os em aÃ§Ãµes como movimentar o cursor, rolar pÃ¡ginas, clicar ou abrir programas.

Foram utilizadas bibliotecas como **OpenCV** (para captura e processamento de imagem), **MediaPipe** (para detecÃ§Ã£o de mÃ£os e extraÃ§Ã£o de pontos-chave) e **PyAutoGUI** (para enviar comandos ao sistema operacional como se fossem aÃ§Ãµes fÃ­sicas do mouse).

Participei diretamente da estruturaÃ§Ã£o lÃ³gica do projeto, integraÃ§Ã£o das bibliotecas e testes. Dois colegas colaboraram com ajustes e testes durante o desenvolvimento.

---

### âš™ï¸ Funcionalidades

- ğŸ–±ï¸ Controle do cursor e cliques por gestos
- ğŸ”„ Rolagem automÃ¡tica com movimentos verticais
- ğŸ”Š Atalhos personalizados, como ajuste de volume
- ğŸ–¥ï¸ Reconhecimento visual com feedback na tela
- âš¡ ExecuÃ§Ã£o rÃ¡pida de aÃ§Ãµes automatizadas

---

### ğŸ’» Tecnologias e Bibliotecas

- **Python**: linguagem principal do projeto
- **OpenCV**: captura e tratamento de imagens da webcam
- **MediaPipe**: detecÃ§Ã£o dos pontos das mÃ£os e gestos
- **PyAutoGUI**: envio de comandos ao sistema, como cliques e rolagem

---

### ğŸš€ Como Executar o Projeto

```bash
# 1. Clone o repositÃ³rio
$ git clone https://github.com/seu-usuario/motion-control

# 2. Extraia o projeto se estiver compactado
# (Por exemplo, clique com o botÃ£o direito e selecione "Extrair aqui")

# 3. Acesse a pasta do projeto
$ cd motion-control

# 4. (Opcional) Crie um ambiente virtual
$ python -m venv venv
$ source venv/bin/activate        # Linux/Mac
$ .\venv\Scripts\activate         # Windows

# 5. Instale as dependÃªncias
$ pip install opencv-python mediapipe pyautogui

# 6. Execute a aplicaÃ§Ã£o
$ python main.py
```

> âš ï¸ Ã‰ necessÃ¡rio ter uma webcam conectada para funcionamento.

---

### ğŸ¤ ParticipaÃ§Ã£o no Projeto

- ğŸ‘¨â€ğŸ’» ProgramaÃ§Ã£o principal, lÃ³gica de controle e integraÃ§Ã£o das bibliotecas: **eu**
- ğŸ§ª Testes e validaÃ§Ã£o prÃ¡tica: **dois colegas**

---

### ğŸ“¬ Contato

[![GitHub](https://img.shields.io/badge/GitHub-1B67A4?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Ramon-24)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/seu-perfil)
[![PortfÃ³lio](https://img.shields.io/badge/Portf%C3%B3lio-1B67A4?style=for-the-badge&logo=google-chrome&logoColor=white)](https://seuportfÃ³lio.com)

---
